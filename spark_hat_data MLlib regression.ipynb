{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%python is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sc = SparkContext.getOrCreate()\n",
    "#\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "#sc = SparkContext.getOrCreate()\n",
    "#spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hats2 = spark.read.csv(\"hats_data.csv\", header=\"true\", inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pants = spark.read.csv(\"pants_data.csv\", header=\"true\", inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pants = pants.select(\"size\",\"cost\",\"color\").filter(col(\"color\") == \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+\n",
      "|color|size|cost|\n",
      "+-----+----+----+\n",
      "|    1|   1| 106|\n",
      "|    2|   1|  73|\n",
      "|    3|   1|  57|\n",
      "|    3|   2|  39|\n",
      "|    2|   1| 104|\n",
      "+-----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pants.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STARTING ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['color', 'size'], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pants = vectorAssembler.transform(pants)\n",
    "pants = pants.select(['features', 'cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "| features|cost|\n",
      "+---------+----+\n",
      "|[1.0,1.0]| 106|\n",
      "|[2.0,1.0]|  73|\n",
      "|[3.0,1.0]|  57|\n",
      "|[3.0,2.0]|  39|\n",
      "|[2.0,1.0]| 104|\n",
      "+---------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df  = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "| features|cost|\n",
      "+---------+----+\n",
      "|[1.0,1.0]| 106|\n",
      "|[1.0,1.0]| 136|\n",
      "|[1.0,1.0]| 166|\n",
      "|[1.0,1.0]| 171|\n",
      "|[1.0,1.0]| 179|\n",
      "+---------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='cost', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit 2 models, using different regularization parameters\n",
    "modelA = lr.fit(train_df)\n",
    "#modelB = lr.fit(tdata, {lr.regParam:100.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, cost: int, prediction: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictionsA = modelA.transform(test_df)\n",
    "display(predictionsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------------+\n",
      "| features|cost|        prediction|\n",
      "+---------+----+------------------+\n",
      "|[1.0,1.0]| 106| 79.49577944200186|\n",
      "|[1.0,1.0]| 136| 79.49577944200186|\n",
      "|[1.0,1.0]| 166| 79.49577944200186|\n",
      "|[1.0,1.0]| 171| 79.49577944200186|\n",
      "|[1.0,1.0]| 179| 79.49577944200186|\n",
      "|[1.0,2.0]|  30| 154.1521462284602|\n",
      "|[1.0,2.0]| 182| 154.1521462284602|\n",
      "|[1.0,2.0]| 184| 154.1521462284602|\n",
      "|[2.0,1.0]|  34|102.80638875345979|\n",
      "|[2.0,2.0]|  47| 177.4627555399181|\n",
      "|[2.0,2.0]| 170| 177.4627555399181|\n",
      "|[3.0,1.0]|  57|126.11699806491772|\n",
      "|[3.0,1.0]| 121|126.11699806491772|\n",
      "|[3.0,1.0]| 134|126.11699806491772|\n",
      "|[3.0,1.0]| 181|126.11699806491772|\n",
      "|[3.0,2.0]|  39|200.77336485137602|\n",
      "|[3.0,3.0]| 288| 275.4297316378344|\n",
      "|[3.0,4.0]| 174| 350.0860984242927|\n",
      "|[3.0,4.0]| 373| 350.0860984242927|\n",
      "|[3.0,5.0]| 546|  424.742465210751|\n",
      "|[4.0,1.0]|  28|149.42760737637562|\n",
      "|[4.0,1.0]|  28|149.42760737637562|\n",
      "|[4.0,1.0]|  39|149.42760737637562|\n",
      "|[4.0,1.0]|  39|149.42760737637562|\n",
      "|[4.0,1.0]|  88|149.42760737637562|\n",
      "|[4.0,1.0]|  98|149.42760737637562|\n",
      "|[4.0,2.0]|  56|224.08397416283395|\n",
      "|[4.0,2.0]|  66|224.08397416283395|\n",
      "|[4.0,2.0]|  88|224.08397416283395|\n",
      "|[4.0,2.0]| 106|224.08397416283395|\n",
      "|[4.0,2.0]| 163|224.08397416283395|\n",
      "|[4.0,2.0]| 172|224.08397416283395|\n",
      "|[4.0,2.0]| 174|224.08397416283395|\n",
      "|[4.0,2.0]| 366|224.08397416283395|\n",
      "|[4.0,3.0]| 403|298.74034094929226|\n",
      "|[4.0,4.0]| 464| 373.3967077357506|\n",
      "|[4.0,4.0]| 629| 373.3967077357506|\n",
      "|[5.0,2.0]| 612| 247.3945834742919|\n",
      "|[5.0,3.0]| 192| 322.0509502607502|\n",
      "|[5.0,4.0]| 570|396.70731704720856|\n",
      "|[5.0,5.0]| 257|471.36368383366687|\n",
      "|[5.0,5.0]| 432|471.36368383366687|\n",
      "|[5.0,5.0]| 481|471.36368383366687|\n",
      "|[6.0,4.0]| 319|420.01792635866644|\n",
      "|[7.0,2.0]| 634| 294.0158020972077|\n",
      "|[7.0,5.0]| 416| 517.9849024565827|\n",
      "+---------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsA.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 147.901822\n",
      "r2: 0.426089\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = modelA.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
