{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%python is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sc = SparkContext.getOrCreate()\n",
    "#\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "#sc = SparkContext.getOrCreate()\n",
    "#spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hats = spark.read.csv(\"hats_data.csv\", header=\"true\", inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pants = spark.read.csv(\"pants_data.csv\", header=\"true\", inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pants = pants.select(\"size\",\"cost\",\"color\").filter(col(\"color\") == \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+-----+\n",
      "|color|size|price|brand|\n",
      "+-----+----+-----+-----+\n",
      "|    0|  31| 1349|    1|\n",
      "|    2|  30| 2079|    1|\n",
      "|    1|  30| 1609|    1|\n",
      "|    2|  32| 2230|    1|\n",
      "|    2|  31| 1565|    1|\n",
      "+-----+----+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hats.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STARTING ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['color', 'size', 'price'], outputCol = 'features')\n",
    "#vectorAssembler_label = VectorAssembler(inputCols = ['brand'], outputCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vectorAssembler.transform(data)\n",
    "#data = vectorAssembler_label.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+-----+-----------------+\n",
      "|color|size|price|brand|         features|\n",
      "+-----+----+-----+-----+-----------------+\n",
      "|    0|  31| 1349|    1|[0.0,31.0,1349.0]|\n",
      "|    2|  30| 2079|    1|[2.0,30.0,2079.0]|\n",
      "|    1|  30| 1609|    1|[1.0,30.0,1609.0]|\n",
      "|    2|  32| 2230|    1|[2.0,32.0,2230.0]|\n",
      "|    2|  31| 1565|    1|[2.0,31.0,1565.0]|\n",
      "+-----+----+-----+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|brand|\n",
      "+-----------------+-----+\n",
      "|[0.0,31.0,1349.0]|    1|\n",
      "|[2.0,30.0,2079.0]|    1|\n",
      "|[1.0,30.0,1609.0]|    1|\n",
      "|[2.0,32.0,2230.0]|    1|\n",
      "|[2.0,31.0,1565.0]|    1|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.select('features', 'brand')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df  = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|brand|\n",
      "+-----------------+-----+\n",
      "|[0.0,28.0,1378.0]|    1|\n",
      "|[0.0,29.0,2111.0]|    1|\n",
      "|[0.0,30.0,1553.0]|    1|\n",
      "+-----------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "rf1 = RandomForestClassifier(featuresCol=\"features\", labelCol=\"brand\", numTrees=10)\n",
    "rf2 = RandomForestClassifier(featuresCol=\"features\", labelCol=\"brand\", numTrees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = rf1.fit(train_df)\n",
    "model2 = rf2.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, brand: int, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions1 = model2.transform(test_df)\n",
    "display(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|         features|brand|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|[0.0,30.0,1696.0]|    1|[0.0,98.897300944...|[0.0,0.9889730094...|       1.0|\n",
      "|[0.0,30.0,2717.0]|    1|[0.0,98.476467611...|[0.0,0.9847646761...|       1.0|\n",
      "|[1.0,28.0,2162.0]|    1|[0.0,99.3125,0.0,...|[0.0,0.993125,0.0...|       1.0|\n",
      "|[1.0,28.0,2533.0]|    1|[0.0,99.3125,0.0,...|[0.0,0.993125,0.0...|       1.0|\n",
      "|[1.0,28.0,2682.0]|    1|[0.0,99.3125,0.0,...|[0.0,0.993125,0.0...|       1.0|\n",
      "|[1.0,28.0,2710.0]|    1|[0.0,99.3125,0.0,...|[0.0,0.993125,0.0...|       1.0|\n",
      "|[1.0,30.0,2331.0]|    1|[0.0,98.476467611...|[0.0,0.9847646761...|       1.0|\n",
      "| [2.0,29.0,810.0]|    1|[0.0,95.0,0.0,2.3...|[0.0,0.95,0.0,0.0...|       1.0|\n",
      "|[2.0,29.0,1273.0]|    1|[0.0,99.0,0.0,0.0...|[0.0,0.99,0.0,0.0...|       1.0|\n",
      "|[2.0,30.0,2079.0]|    1|[0.0,98.476467611...|[0.0,0.9847646761...|       1.0|\n",
      "| [2.0,31.0,961.0]|    1|[0.0,93.173993558...|[0.0,0.9317399355...|       1.0|\n",
      "|[2.0,31.0,1045.0]|    1|[0.0,93.173993558...|[0.0,0.9317399355...|       1.0|\n",
      "|[2.0,31.0,1168.0]|    1|[0.0,93.173993558...|[0.0,0.9317399355...|       1.0|\n",
      "| [3.0,6.0,2471.0]|    2|[0.0,0.0,100.0,0....|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "| [3.0,6.0,3763.0]|    2|[0.0,0.0,100.0,0....|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "| [3.0,7.0,3013.0]|    2|[0.0,0.0,100.0,0....|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "| [3.0,7.0,3379.0]|    2|[0.0,0.0,100.0,0....|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "| [3.0,8.0,1570.0]|    2|[0.0,0.0,100.0,0....|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "| [3.0,8.0,2475.0]|    2|[0.0,0.0,100.0,0....|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "| [3.0,9.0,3401.0]|    2|[0.0,0.0,100.0,0....|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions1.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------------+\n",
      "|prediction|brand|         features|\n",
      "+----------+-----+-----------------+\n",
      "|       1.0|    1|[0.0,30.0,1696.0]|\n",
      "|       1.0|    1|[0.0,30.0,2717.0]|\n",
      "|       1.0|    1|[1.0,28.0,2162.0]|\n",
      "|       1.0|    1|[1.0,28.0,2533.0]|\n",
      "+----------+-----+-----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = predictions1\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"brand\", \"features\").show(4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.111111\n",
      "accuracy is 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"brand\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print('accuracy is', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
